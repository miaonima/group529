{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sklearn import model_selection, linear_model, metrics, pipeline, preprocessing\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and separate the id's\n",
    "X_data  = pd.read_hdf(\"cat.hdf5\", \"train\")\n",
    "y_data  = pd.read_hdf(\"cat.hdf5\", \"train_target\")\n",
    "X_test  = pd.read_hdf(\"cat.hdf5\", \"test\")\n",
    "\n",
    "# Store and drop data ID\n",
    "data_id = X_data.loc[:, \"id\"]\n",
    "test_id = X_test.loc[:, \"id\"]\n",
    "\n",
    "X_data.drop(columns=\"id\", inplace=True)\n",
    "X_test.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"cat.hdf5\", \"r\") as f:\n",
    "    data_columns, one_hot_columns = f['data_columns'][()],f['one_hot_columns'][()]\n",
    "\n",
    "data_columns = list(data_columns.astype(\"U\"))\n",
    "one_hot_columns = list(one_hot_columns.astype(\"U\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data with labels into training and validation.\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_data, y_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210000, 291) (210000,) (90000, 291) (90000,) (200000, 291)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column selector in the pipeline\n",
    "Adapted from https://ramhiser.com/post/2018-04-16-building-scikit-learn-pipeline-with-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"The DataFrame does not include the columns: %s\" % cols_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate our two selectors\n",
    "label_encode_selector = ColumnSelector(data_columns)\n",
    "one_hot_selector = ColumnSelector(one_hot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1', 'nom_2',\n",
      "       'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
      "       'nom_5_freq', 'nom_6_freq', 'nom_7_freq', 'nom_8_freq', 'nom_9_freq',\n",
      "       'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day_sin',\n",
      "       'day_cos', 'month_sin', 'month_cos'],\n",
      "      dtype='object')\n",
      "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0_Green', 'nom_0_Red',\n",
      "       'nom_1_Polygon', 'nom_1_Square', 'nom_1_Star',\n",
      "       ...\n",
      "       'ord_5_186', 'ord_5_187', 'ord_5_188', 'ord_5_189', 'ord_5_190',\n",
      "       'ord_5_191', 'day_sin', 'day_cos', 'month_sin', 'month_cos'],\n",
      "      dtype='object', length=275)\n"
     ]
    }
   ],
   "source": [
    "print(label_encode_selector.fit_transform(X_train).columns)\n",
    "print(one_hot_selector.fit_transform(X_train).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitic Regression as baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", linear_model.LogisticRegressionCV(\n",
    "            solver=\"lbfgs\", max_iter=2000, cv=5, n_jobs=-1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "logistic.fit(X_train_dmy, y_train_dmy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model):\n",
    "    y_val_pred = model.predict_proba(X_val_dmy)[:, 1]\n",
    "    val_score = metrics.roc_auc_score(y_val_dmy, y_val_pred)\n",
    "\n",
    "    y_train_pred = model.predict_proba(X_train_dmy)[:, 1]\n",
    "    train_score = metrics.roc_auc_score(y_train_dmy, y_train_pred)\n",
    "\n",
    "    return (train_score, val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not use GridSearchCV:\n",
    "# See https://github.com/dmlc/xgboost/issues/2819\n",
    "# Instead we implement our own grid search.\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import itertools\n",
    "\n",
    "# Takes a parameter grid similar to the format in\n",
    "# sklearn GridSearchCV and returns a list of names every time.\n",
    "def get_grid_iter(param_grid):\n",
    "    names = []\n",
    "    values = []\n",
    "    \n",
    "    for param_name, param_values in param_grid.items():\n",
    "        names.append(param_name)\n",
    "        \n",
    "        if isinstance(param_values, list):\n",
    "            values.append(list(param_values))\n",
    "        else:\n",
    "            values.append(list([param_values]))\n",
    "    \n",
    "    it = (dict(zip(names, param)) for param in itertools.product(*values))\n",
    "    item_cnt = np.prod(np.array([len(v) for v in values]))\n",
    "    return it, item_cnt\n",
    "\n",
    "# Similar to GridSearchCV\n",
    "def hyper_opt(model_base, param_grid, metric, X_train, y_train, X_val, y_val, bin_prob, verbose=False):\n",
    "    best_param = None\n",
    "    best_param_id = -1\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    it, item_cnt = get_grid_iter(param_grid)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for param in it:\n",
    "        \n",
    "        model = model_base(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        if bin_prob:\n",
    "            y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        train_score = metric(y_train, y_train_pred)\n",
    "        val_score = metric(y_val, y_val_pred)\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_param = param\n",
    "            best_param_id = step\n",
    "        \n",
    "        step += 1\n",
    "        if verbose:\n",
    "            print(\"[%d/%d] train:%f test:%f best:%f id:%d\" %\n",
    "                (step, item_cnt, train_score, val_score, best_score, best_param_id))\n",
    "            \n",
    "    return best_score, best_param, best_param_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [500, 1000, 1500, 2500, 3000],\n",
    "    'max_depth':[1, 2, 3, 4, 5],\n",
    "    'objective':'binary:logistic',\n",
    "    'subsample':[0.6, 0.8, 1], \n",
    "    'colsample_bytree':[0.6, 0.8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    'tree_method':'gpu_hist',\n",
    "    'evalmetric':'auc'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#score, param, param_id = hyper_opt(XGBClassifier, xgb_param_grid, metrics.roc_auc_score,\n",
    "#          X_train, y_train, X_val, y_val,\n",
    "#          bin_prob=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_id = 587\n",
    "best_param = list(get_grid_iter(xgb_param_grid)[0])[param_id]\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb  = XGBClassifier(**best_param)\n",
    "xgb.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_proba   = logistic.predict_proba(X_test)[:, 1]\n",
    "xgb_proba        = xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_score   = logistic.score(X_val,y_val)\n",
    "xgb_score        = xgb.score(X_val,y_val)\n",
    "\n",
    "logistic_weight  = logistic_score/(logistic_score + xgb_score)\n",
    "xgb_weight       = xgb_score/(logistic_score + xgb_score)\n",
    "\n",
    "target           = logistic_proba*logistic_weight + xgb_proba*xgb_weight\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": test_id,\n",
    "        \"target\": target\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check X_train AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_proba   = logistic.predict_proba(X_data)[:, 1]\n",
    "xgb_proba        = xgb.predict_proba(X_data)[:,1]\n",
    "\n",
    "target           = logistic_proba*logistic_weight + xgb_proba*xgb_weight\n",
    "logistic_roc     = metrics.roc_auc_score(y_data, logistic_proba)\n",
    "xgb_roc          = metrics.roc_auc_score(y_data, xgb_proba)\n",
    "target_roc       = metrics.roc_auc_score(y_data, target)\n",
    "\n",
    "print('logistic_roc: %f,  xgb_roc: %f,  target_roc: %f,'%(logistic_roc, xgb_roc, target_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From above we know that Logistics Regression does not work well. Kick it off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", SVC(gamma='auto',probability=True))\n",
    "        ])\n",
    "\n",
    "knn = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", KNeighborsClassifier(n_neighbors = 3,n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "logistic = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", LogisticRegression(solver='lbfgs',n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "rf = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", RandomForestClassifier(n_estimators=100,n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "nb = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", GaussianNB())\n",
    "        ])\n",
    "\n",
    "perceptron = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", Perceptron(n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "sgd = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", SGDClassifier(n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "lsvc = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", LinearSVC(max_iter=10000))\n",
    "        ])\n",
    "\n",
    "decision_tree = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", DecisionTreeClassifier())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_list = []\n",
    "val_score_list   = []\n",
    "\n",
    "model_dict = {\n",
    "             'Random Forest':rf,\n",
    "             'Decision Tree':decision_tree\n",
    "             }\n",
    "\n",
    "model_dict_dmy = {\n",
    "             'Support Vector Machines':svc,\n",
    "             'KNN':knn,\n",
    "             'Logistic Regression':logistic,\n",
    "             'Naive Bayes':nb,\n",
    "             'Perceptron':perceptron,\n",
    "             'Stochastic Gradient Descent':sgd,\n",
    "             'Linear SVC':lsvc,\n",
    "             }\n",
    "for model_name,model in model_dict.items():\n",
    "    train_score, val_score = get_roc(model,X_train,y_train,X_val,y_val)\n",
    "    train_score_list.append(train_score)\n",
    "    val_score_list.append(val_score)\n",
    "    \n",
    "for model_name,model in model_dict_dmy.items():\n",
    "    train_score, val_score = get_roc(model,X_train_dmy,y_train_dmy,X_val_dmy,y_val_dmy)\n",
    "    train_score_list.append(train_score)\n",
    "    val_score_list.append(val_score)\n",
    "    \n",
    "\n",
    "score_pd = pd.DataFrame({'model':list(model_dict.keys()),'Train score':train_score_list, \n",
    "                         'Validation score':val_score_list}) \n",
    "score_pd.sort_values(by='Validation score', ascending=False)\n",
    "score_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
