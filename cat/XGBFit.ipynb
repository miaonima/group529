{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sklearn import model_selection, linear_model, metrics, pipeline, preprocessing\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and separate the id's\n",
    "X_data  = pd.read_hdf(\"cat.hdf5\", \"train\")\n",
    "y_data  = pd.read_hdf(\"cat.hdf5\", \"train_target\")\n",
    "X_test  = pd.read_hdf(\"cat.hdf5\", \"test\")\n",
    "\n",
    "# Store and drop data ID\n",
    "data_id = X_data.loc[:, \"id\"]\n",
    "test_id = X_test.loc[:, \"id\"]\n",
    "\n",
    "X_data.drop(columns=\"id\", inplace=True)\n",
    "X_test.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"cat.hdf5\", \"r\") as f:\n",
    "    data_columns = f['data_columns'][()]\n",
    "    one_hot_columns = f['one_hot_columns'][()]\n",
    "\n",
    "data_columns = list(data_columns.astype(\"U\"))\n",
    "one_hot_columns = list(one_hot_columns.astype(\"U\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data with labels into training and validation.\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_data, y_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210000, 291) (210000,) (90000, 291) (90000,) (200000, 291)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column selector in the pipeline\n",
    "Adapted from https://ramhiser.com/post/2018-04-16-building-scikit-learn-pipeline-with-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"The DataFrame does not include the columns: %s\" % cols_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate our two selectors\n",
    "label_encode_selector = ColumnSelector(data_columns)\n",
    "one_hot_selector = ColumnSelector(one_hot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1', 'nom_2',\n",
      "       'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
      "       'nom_5_freq', 'nom_6_freq', 'nom_7_freq', 'nom_8_freq', 'nom_9_freq',\n",
      "       'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day_sin',\n",
      "       'day_cos', 'month_sin', 'month_cos'],\n",
      "      dtype='object')\n",
      "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0_Green', 'nom_0_Red',\n",
      "       'nom_1_Polygon', 'nom_1_Square', 'nom_1_Star',\n",
      "       ...\n",
      "       'ord_5_186', 'ord_5_187', 'ord_5_188', 'ord_5_189', 'ord_5_190',\n",
      "       'ord_5_191', 'day_sin', 'day_cos', 'month_sin', 'month_cos'],\n",
      "      dtype='object', length=275)\n"
     ]
    }
   ],
   "source": [
    "print(label_encode_selector.fit_transform(X_train).columns)\n",
    "print(one_hot_selector.fit_transform(X_train).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premilinary Model Selection\n",
    "We use these model without tuning to see their basic performance on the dataset, and use this to decide whether it is even worth tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# SVC does not scale up; but we try them anyway\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Likely wont work; this is not Gaussian or even approx Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = pipeline.Pipeline([\n",
    "        (\"one_hot_selector\", one_hot_selector),\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"clf\", SVC(gamma='auto',probability=True))\n",
    "        ])\n",
    "\n",
    "logistic = pipeline.Pipeline([    \n",
    "        (\"one_hot_selector\", one_hot_selector),\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"clf\", LogisticRegressionCV(cv=5,solver='lbfgs',max_iter=10000,n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "rf = pipeline.Pipeline([\n",
    "        (\"label_encode_selector\", label_encode_selector),\n",
    "        (\"clf\", RandomForestClassifier(n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "nb = pipeline.Pipeline([\n",
    "        (\"one_hot_selector\", one_hot_selector),\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"clf\", GaussianNB())\n",
    "        ])\n",
    "\n",
    "sgd = pipeline.Pipeline([\n",
    "        (\"one_hot_selector\", one_hot_selector),\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "    # We use log so that it does not predict 0/1 only\n",
    "        (\"clf\", SGDClassifier(loss=\"log\",n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "decision_tree = pipeline.Pipeline([\n",
    "        (\"label_encode_selector\", label_encode_selector),\n",
    "        (\"clf\", DecisionTreeClassifier())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# This function evaluates a model use a subset of training data,\n",
    "# and a validation set. Also time the training and prediction.\n",
    "def get_score(model, limit_train_size=None, limit_val_size=None):\n",
    "    if limit_train_size == None:\n",
    "        X_t = X_train\n",
    "        y_t = y_train\n",
    "    else:\n",
    "        X_t = X_train[:limit_train_size]\n",
    "        y_t = y_train[:limit_train_size]\n",
    "        \n",
    "    if limit_train_size == None:\n",
    "        X_t = X_val\n",
    "        y_t = y_val\n",
    "    else:\n",
    "        X_t = X_val[:limit_val_size]\n",
    "        y_t = y_val[:limit_val_size]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.fit(X_t, y_t)\n",
    "    \n",
    "    \n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    val_score = metrics.roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "    y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "    train_score = metrics.roc_auc_score(y_train, y_train_pred)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    dt = t1 - t0\n",
    "    \n",
    "    return (train_score, val_score, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating svc.\n",
      "Evaluating logistic.\n",
      "Evaluating rf.\n",
      "Evaluating nb.\n",
      "Evaluating sgd.\n",
      "Evaluating decision_tree.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.688313</td>\n",
       "      <td>0.691235</td>\n",
       "      <td>41.718692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.695031</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>3.010755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.690759</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.944206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.506956</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>3.497842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sgd</td>\n",
       "      <td>0.662212</td>\n",
       "      <td>0.668055</td>\n",
       "      <td>1.869616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.551149</td>\n",
       "      <td>0.558607</td>\n",
       "      <td>0.192563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             clf  Train AUC  Validation AUC       Time\n",
       "0            svc   0.688313        0.691235  41.718692\n",
       "1       logistic   0.695031        0.699301   3.010755\n",
       "2             rf   0.690759        0.695558   0.944206\n",
       "3             nb   0.506956        0.509400   3.497842\n",
       "4            sgd   0.662212        0.668055   1.869616\n",
       "5  decision_tree   0.551149        0.558607   0.192563"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_name = [\"svc\", \"logistic\", \"rf\",\n",
    "            \"nb\", \"sgd\", \"decision_tree\"]\n",
    "clfs = [svc, logistic, rf, nb, sgd, decision_tree]\n",
    "\n",
    "train_auc = []\n",
    "val_auc = []\n",
    "time_elapsed = []\n",
    "\n",
    "for i, clf in enumerate(clfs):\n",
    "    print(\"Evaluating %s.\" % clf_name[i])\n",
    "    train, val, t = get_score(clf,\n",
    "        limit_train_size=1000, limit_val_size=1000)\n",
    "    train_auc.append(train)\n",
    "    val_auc.append(val)\n",
    "    time_elapsed.append(t)\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"clf\": clf_name,\n",
    "        \"Train AUC\": train_auc,\n",
    "        \"Validation AUC\": val_auc,\n",
    "        \"Time\": time_elapsed\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Although SVC result looks primising, it indeed does not scale well; we shall remove this. Also we remove sgd, Naive Bayes and Decision Tree in favor of Logistic Regression, Random Forest and probably XGB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not use GridSearchCV:\n",
    "# See https://github.com/dmlc/xgboost/issues/2819\n",
    "# Instead we implement our own grid search.\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import itertools\n",
    "\n",
    "# Takes a parameter grid similar to the format in\n",
    "# sklearn GridSearchCV and returns a list of names every time.\n",
    "def get_grid_iter(param_grid):\n",
    "    names = []\n",
    "    values = []\n",
    "    \n",
    "    for param_name, param_values in param_grid.items():\n",
    "        names.append(param_name)\n",
    "        \n",
    "        if isinstance(param_values, list):\n",
    "            values.append(list(param_values))\n",
    "        else:\n",
    "            values.append(list([param_values]))\n",
    "    \n",
    "    it = (dict(zip(names, param)) for param in itertools.product(*values))\n",
    "    item_cnt = np.prod(np.array([len(v) for v in values]))\n",
    "    return it, item_cnt\n",
    "\n",
    "# Similar to GridSearchCV\n",
    "def hyper_opt(model_base, param_grid, metric, X_train, y_train, X_val, y_val, bin_prob, verbose=False):\n",
    "    best_param = None\n",
    "    best_param_id = -1\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    it, item_cnt = get_grid_iter(param_grid)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for param in it:\n",
    "        \n",
    "        model = model_base(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        if bin_prob:\n",
    "            y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        train_score = metric(y_train, y_train_pred)\n",
    "        val_score = metric(y_val, y_val_pred)\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_param = param\n",
    "            best_param_id = step\n",
    "        \n",
    "        step += 1\n",
    "        if verbose:\n",
    "            print(\"[%d/%d] train:%f test:%f best:%f id:%d\" %\n",
    "                (step, item_cnt, train_score, val_score, best_score, best_param_id))\n",
    "            \n",
    "    return best_score, best_param, best_param_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used this grid for searching; for demonstration purposes\n",
    "# we only use a very coarse grid here. For the finer grid, see\n",
    "# appendix.\n",
    "\n",
    "#xgb_param_grid = {\n",
    "#    \"n_estimators\": [500, 1000, 1500, 2000, 3000],\n",
    "#    'max_depth':[1, 2, 3, 4, 5],\n",
    "#    'objective':'binary:logistic',\n",
    "#    'subsample':[0.6, 0.8, 1], \n",
    "#    'colsample_bytree':[0.6, 0.8, 1],\n",
    "#    'learning_rate':[0.01, 0.1],\n",
    "#    'tree_method':'gpu_hist'\n",
    "#}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [500, 1000, 1500],\n",
    "    'max_depth':[1, 2],\n",
    "    'objective':'binary:logistic',\n",
    "    'subsample':[1], \n",
    "    'colsample_bytree':[1],\n",
    "    'learning_rate':[0.01, 0.1],\n",
    "    'tree_method':'gpu_hist'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] train:0.723428 test:0.725072 best:0.725072 id:0\n",
      "[2/12] train:0.765054 test:0.765870 best:0.765870 id:1\n",
      "[3/12] train:0.745858 test:0.738058 best:0.765870 id:1\n",
      "[4/12] train:0.797647 test:0.762119 best:0.765870 id:1\n",
      "[5/12] train:0.739944 test:0.742845 best:0.765870 id:1\n",
      "[6/12] train:0.770691 test:0.767322 best:0.767322 id:5\n",
      "[7/12] train:0.764020 test:0.755522 best:0.767322 id:5\n",
      "[8/12] train:0.820151 test:0.761066 best:0.767322 id:5\n",
      "[9/12] train:0.749426 test:0.752734 best:0.767322 id:5\n",
      "[10/12] train:0.773744 test:0.767915 best:0.767915 id:9\n",
      "[11/12] train:0.771627 test:0.760466 best:0.767915 id:9\n",
      "[12/12] train:0.835652 test:0.759309 best:0.767915 id:9\n",
      "{'n_estimators': 1500, 'max_depth': 1, 'objective': 'binary:logistic', 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.1, 'tree_method': 'gpu_hist'}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_t = 20000\n",
    "N_v = 10000\n",
    "X_t = label_encode_selector.fit_transform(X_train[:N_t])\n",
    "X_v = label_encode_selector.fit_transform(X_val[:N_v])\n",
    "y_t = y_train[:N_t]\n",
    "y_v = y_val[:N_v]\n",
    "\n",
    "score, param, param_id = hyper_opt(XGBClassifier, xgb_param_grid, metrics.roc_auc_score,\n",
    "          X_t, y_t, X_v, y_v,\n",
    "          bin_prob=True, verbose=True)\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the best parameter found in the larger and\n",
    "# finer grid and fit the full data.\n",
    "best_param = {\n",
    "    'n_estimators': 3000,\n",
    "    'max_depth': 2,\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'learning_rate': 0.1,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"label_encode_selector\", label_encode_selector),\n",
    "        (\"xgb\", XGBClassifier(**best_param))\n",
    "    ] \n",
    ")\n",
    "xgb.fit(X_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 30 artists>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's see the feature importances for checking\n",
    "imp = pd.Series(\n",
    "    data=xgb[\"xgb\"].feature_importances_,\n",
    "    index=data_columns\n",
    ").sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(imp.index, imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: it seems that high cardinality nominal variables are not so important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now fit the other two models as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7620609770095521"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# To avoid OOM, we limit the training size.\n",
    "N_logistic = 50000\n",
    "choice = np.random.choice(len(X_data), size=N_logistic)\n",
    "\n",
    "logistic.fit(X_data.loc[choice, :], y_data[choice]);\n",
    "\n",
    "y_data_hat = logistic.predict_proba(X_data)[:, 1]\n",
    "\n",
    "# Our final training score for logistic regression\n",
    "metrics.roc_auc_score(y_data, y_data_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.724727764774564"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For random forest, we use GridSearchCV to tune the parameters.\n",
    "N_rf = 50000\n",
    "choice = np.random.choice(len(X_data), size=N_rf)\n",
    "\n",
    "rf_grid = {\n",
    "    \"clf__n_estimators\": [200, 500, 1000, 2000],\n",
    "    \"clf__max_depth\": [1, 2],\n",
    "    \"clf__criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "rf_cv = model_selection.GridSearchCV(rf, rf_grid,\n",
    "        cv=3, scoring=\"roc_auc\")\n",
    "rf_cv.fit(X_data[:N_rf], y_data[:N_rf])\n",
    "\n",
    "y_data_hat = rf_cv.predict_proba(X_data)[:, 1]\n",
    "\n",
    "# Our final training score for RF\n",
    "metrics.roc_auc_score(y_data, y_data_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_proba = logistic.predict_proba(X_test)[:, 1]\n",
    "xgb_proba = xgb.predict_proba(X_test)[:,1]\n",
    "rf_proba = rf_cv.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted voting\n",
    "target = 0.7 * xgb_proba + 0.2 * logistic_proba + 0.1 * rf_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": test_id,\n",
    "        \"target\": target\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: this achieves 0.78598 AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
